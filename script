import os
from posixpath import join as pjoin
from posixpath import split as psplit

import torch
from torch import optim

from models.base_model import BaseModel
from models.integrated import IntegratedModel
from models.utils import (Criterion_EE, Criterion_EE_2, Eval_Criterion,
                          GAN_loss, ImagePool, get_ee)


class DeepMotionTargeting(torch.nn.Module):
    def __init__(self, args, character_names, dataset):
        super(DeepMotionTargeting, self).__init__()        
        self.args = args
        self.is_train = args.is_train
        self.device = torch.device(
            args.cuda_device if (torch.cuda.is_available()) else "cpu"
        )
        self.model_save_dir = pjoin(
            args.save_dir, "models"
        )  # save all the checkpoints to save_dir

        if self.is_train:
            from loss_record import LossRecorder
            from torch.utils.tensorboard import SummaryWriter

            self.log_path = pjoin(args.save_dir, "logs")
            self.writer = SummaryWriter(self.log_path)
            self.loss_recoder = LossRecorder(self.writer)

        self.epoch_cnt = 0
        self.schedulers = []
        self.optimizers = []
        self.character_names = character_names
        self.dataset = dataset
        self.n_topology = len(character_names)
        self.models = []
        self.D_para = []
        self.G_para = []
        self.args = args

        for i in range(self.n_topology):
            model = IntegratedModel(
                args, dataset.joint_topologies[i], None, self.device, character_names[i]
            )
            self.models.append(model)
            self.D_para += model.D_parameters()
            self.G_para += model.G_parameters()

        if self.is_train:
            self.fake_pools = []
            self.optimizerD = optim.Adam(
                self.D_para, args.learning_rate, betas=(0.9, 0.999)
            )
            self.optimizerG = optim.Adam(
                self.G_para, args.learning_rate, betas=(0.9, 0.999)
            )
            self.optimizers = [self.optimizerD, self.optimizerG]
            self.criterion_rec = torch.nn.MSELoss()
            self.criterion_gan = GAN_loss(args.gan_mode).to(self.device)
            self.criterion_cycle = torch.nn.L1Loss()
            self.criterion_ee = Criterion_EE(args, torch.nn.MSELoss())
            for i in range(self.n_topology):
                self.fake_pools.append(ImagePool(args.pool_size))
        else:
            import option_parser

            self.err_crit = []
            for i in range(self.n_topology):
                self.err_crit.append(Eval_Criterion(dataset.joint_topologies[i]))
            self.id_test = 0
            self.bvh_path = pjoin(args.save_dir, "results/bvh")
            option_parser.try_mkdir(self.bvh_path)

            self.writer = []
            for i in range(self.n_topology):
                writer_group = []
                for _, char in enumerate(character_names[i]):
                    import option_parser
                    from datasets.bvh_parser import BVH_file
                    from datasets.bvh_writer import BVH_writer

                    file = BVH_file(option_parser.get_std_bvh(dataset=char))
                    writer_group.append(BVH_writer(file.edges, file.names))
                self.writer.append(writer_group)                
            self.latents = []
            self.offset_repr = []
            self.pos_ref = []
            self.ee_ref = []
            self.res = []
            self.res_denorm = []
            self.res_pos = []
            self.fake_res = []
            self.fake_res_denorm = []
            self.fake_pos = []
            self.fake_ee = []
            self.fake_latent = []
            self.motions = []
            self.motion_denorm = []
            self.rnd_idx = []

    def get_scheduler(self, optimizer):
        if self.args.scheduler == "linear":

            def lambda_rule(epoch):
                lr_l = 1.0 - max(0, epoch - self.args.n_epochs_origin) / float(
                    self.args.n_epochs_decay + 1
                )
                return lr_l

            return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)
        if self.args.scheduler == "Step_LR":
            print("Step_LR scheduler set")
            return torch.optim.lr_scheduler.StepLR(optimizer, 50, 0.5)
        if self.args.scheduler == "Plateau":
            print("Plateau_LR shceduler set")
            return torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer,
                mode="min",
                factor=0.2,
                threshold=0.01,
                patience=5,
                verbose=True,
            )
        if self.args.scheduler == "MultiStep":
            return torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[])

    def setup(self):
        """Load and print networks; create schedulers
        Parameters:
            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions
        """
        if self.is_train:
            self.schedulers = [
                self.get_scheduler(optimizer) for optimizer in self.optimizers
            ]

    def epoch(self):
        self.loss_recoder.epoch()
        for scheduler in self.schedulers:
            if scheduler is not None:
                scheduler.step()
        self.epoch_cnt += 1

    def test(self):
        """Forward function used in test time.
        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop
        It also calls <compute_visuals> to produce additional visualization results
        """
        with torch.no_grad():
            self.forward()
            self.compute_test_result()

    def forward(self):
        pass
        # for i in range(self.n_topology):
        #     self.offset_repr.append(
        #         self.models[i].static_encoder(self.dataset.offsets[i])
        #     )

        # # reconstruct
        # for i in range(self.n_topology):
        #     motion, offset_idx = self.motions_input[i]
        #     motion = motion.to(self.device)
        #     self.motions.append(motion)

        #     motion_denorm = self.dataset.denorm(i, offset_idx, motion)
        #     self.motion_denorm.append(motion_denorm)
        #     offsets = [
        #         self.offset_repr[i][p][offset_idx]
        #         for p in range(self.args.num_layers + 1)
        #     ]
        #     latent, res = self.models[i].auto_encoder(motion, offsets)
        #     res_denorm = self.dataset.denorm(i, offset_idx, res)
        #     res_pos = self.models[i].fk.forward_from_raw(
        #         res_denorm, self.dataset.offsets[i][offset_idx]
        #     )
        #     self.res_pos.append(res_pos)
        #     self.latents.append(latent)
        #     self.res.append(res)
        #     self.res_denorm.append(res_denorm)

        #     pos = (
        #         self.models[i]
        #         .fk.forward_from_raw(motion_denorm, self.dataset.offsets[i][offset_idx])
        #         .detach()
        #     )
        #     ee = get_ee(
        #         pos,
        #         self.dataset.joint_topologies[i],
        #         self.dataset.ee_ids[i],
        #         velo=self.args.ee_velo,
        #         from_root=self.args.ee_from_root,
        #     )
        #     height = self.models[i].height[offset_idx]
        #     height = height.reshape((height.shape[0], 1, height.shape[1], 1))
        #     ee /= height
        #     self.pos_ref.append(pos)
        #     self.ee_ref.append(ee)

        # # retargeting
        # for src in range(self.n_topology):
        #     for dst in range(self.n_topology):
        #         if self.is_train:
        #             rnd_idx = torch.randint(
        #                 len(self.character_names[dst]), (self.latents[src].shape[0],)
        #             )
        #         else:
        #             rnd_idx = list(range(self.latents[0].shape[0]))
        #         self.rnd_idx.append(rnd_idx)
        #         dst_offsets_repr = [
        #             self.offset_repr[dst][p][rnd_idx]
        #             for p in range(self.args.num_layers + 1)
        #         ]
        #         fake_res = self.models[dst].auto_encoder.dec(
        #             self.latents[src], dst_offsets_repr
        #         )
        #         fake_latent = self.models[dst].auto_encoder.enc(
        #             fake_res, dst_offsets_repr
        #         )

        #         fake_res_denorm = self.dataset.denorm(dst, rnd_idx, fake_res)
        #         fake_pos = self.models[dst].fk.forward_from_raw(
        #             fake_res_denorm, self.dataset.offsets[dst][rnd_idx]
        #         )
        #         fake_ee = get_ee(
        #             fake_pos,
        #             self.dataset.joint_topologies[dst],
        #             self.dataset.ee_ids[dst],
        #             velo=self.args.ee_velo,
        #             from_root=self.args.ee_from_root,
        #         )
        #         height = self.models[dst].height[rnd_idx]
        #         height = height.reshape((height.shape[0], 1, height.shape[1], 1))
        #         fake_ee = fake_ee / height

        #         self.fake_latent.append(fake_latent)
        #         self.fake_pos.append(fake_pos)
        #         self.fake_res.append(fake_res)
        #         self.fake_ee.append(fake_ee)
        #         self.fake_res_denorm.append(fake_res_denorm)
    
    def load(self, epoch=None):
        for i, model in enumerate(self.models):
            model.load(pjoin(self.model_save_dir, "topology{}".format(i)), epoch)

        if self.is_train:
            for i, optimizer in enumerate(self.optimizers):
                file_name = pjoin(
                    self.model_save_dir, "optimizers/{}/{}.pt".format(epoch, i)
                )
                optimizer.load_state_dict(torch.load(file_name))
        self.epoch_cnt = epoch

    def set_input(self, motions):
        self.motions_input = motions

        if not self.is_train:
            self.motion_backup = []
            for i in range(self.n_topology):
                self.motion_backup.append(motions[i][0].clone())
                self.motions_input[i][0][1:] = self.motions_input[i][0][0]
                self.motions_input[i][1] = [0] * len(self.motions_input[i][1])

import os
from models import create_model
from datasets import create_dataset
import option_parser
from shutil import copyfile
from posixpath import join as pjoin
import os
import sys
sys.path.append(".")
from datasets.bvh_parser import BVH_file
from datasets.bvh_writer import BVH_writer
from models.IK import fix_foot_contact

def eval_prepare(args):
    character = []
    file_id = []
    character_names = []
    character_names.append(args.input_bvh.split("/")[-2])
    character_names.append(args.target_bvh.split("/")[-2])
    if args.test_type == "intra":
        if character_names[0].endswith("_m"):
            character = [["BigVegas", "BigVegas"], character_names]
            file_id = [[0, 0], [args.input_bvh, args.input_bvh]]
            src_id = 1
        else:
            character = [character_names, ["Goblin_m", "Goblin_m"]]
            file_id = [[args.input_bvh, args.input_bvh], [0, 0]]
            src_id = 0
    elif args.test_type == "cross":
        if character_names[0].endswith("_m"):
            character = [[character_names[1]], [character_names[0]]]
            file_id = [[0], [args.input_bvh]]
            src_id = 1
        else:
            character = [[character_names[0]], [character_names[1]]]
            file_id = [[args.input_bvh], [0]]
            src_id = 0
    else:
        raise Exception("Unknown test type")
    return character, file_id, src_id


def recover_space(file):
    l = file.split("/")
    l[-1] = l[-1].replace("_", " ")
    return "/".join(l)

def create_script_model(args, character_names, dataset):
    if args.model == "mul_top_mul_ske":
        args.skeleton_info = "concat"
        import models.architecture

        return DeepMotionTargeting(args, character_names, dataset)

    else:
        raise Exception("Unimplemented model")


def main(input_file, ref_file, output_file_name, test_type):
    parser = option_parser.get_parser()
    parser.add_argument("--input_bvh", type=str, required=False)
    parser.add_argument("--target_bvh", type=str, required=False)
    parser.add_argument("--test_type", type=str, required=False)
    parser.add_argument("--output_filename", type=str, required=False)

    args = parser.parse_args()
    args.input_bvh = input_file
    args.target_bvh = ref_file
    args.output_filename = output_file_name
    args.test_type = test_type

    # argsparse can't take space character as part of the argument
    args.input_bvh = recover_space(args.input_bvh)
    args.target_bvh = recover_space(args.target_bvh)
    args.output_filename = recover_space(args.output_filename)

    character_names, file_id, src_id = eval_prepare(args)
    input_character_name = args.input_bvh.split("/")[-2]
    output_character_name = args.target_bvh.split("/")[-2]
    output_filename = args.output_filename

    test_device = args.cuda_device
    eval_seq = args.eval_seq

    para_path = pjoin(args.save_dir, "para.txt")
    with open(para_path, "r") as para_file:
        argv_ = para_file.readline().split()[1:]
        args = option_parser.get_parser().parse_args(argv_)

    args.cuda_device = test_device if torch.cuda.is_available() else "cpu"
    args.is_train = False
    args.rotation = "quaternion"
    args.eval_seq = eval_seq

    dataset = create_dataset(args, character_names)

    model = create_script_model(args, character_names, dataset)
    model.load(epoch=20000)

    input_motion = []
    for i, character_group in enumerate(character_names):
        input_group = []
        for j in range(len(character_group)):
            new_motion = dataset.get_item(i, j, file_id[i][j])
            new_motion.unsqueeze_(0)
            new_motion = (new_motion - dataset.mean[i][j]) / dataset.var[i][j]
            input_group.append(new_motion)
        input_group = torch.cat(input_group, dim=0)
        input_motion.append([input_group, list(range(len(character_group)))])

    model.set_input(input_motion)
    # model.test()
    # bvh_path = "{}/{}/0_{}.bvh".format(model.bvh_path, output_character_name, src_id)
    # copyfile(bvh_path, output_filename)
    sm = torch.jit.script(model)
    print(sm.code)



# downsampling and remove redundant joints
def copy_ref_file(src, dst):
    file = BVH_file(src)
    writer = BVH_writer(file.edges, file.names)
    writer.write_raw(file.to_tensor(quater=True)[..., ::2], 'quaternion', dst)


def get_height(file):
    file = BVH_file(file)
    return file.get_height()


def example(src_name, dest_name, bvh_name, test_type, output_path):
    if not os.path.exists(output_path):
        os.makedirs(output_path)

    input_file = './datasets/Mixamo/{}/{}'.format(src_name, bvh_name)
    ref_file = './datasets/Mixamo/{}/{}'.format(dest_name, bvh_name)
    copy_ref_file(input_file, pjoin(output_path, 'input.bvh'))
    copy_ref_file(ref_file, pjoin(output_path, 'gt.bvh'))
    height = get_height(input_file)

    bvh_name = bvh_name.replace(' ', '_')
    input_file = './datasets/Mixamo/{}/{}'.format(src_name, bvh_name)
    ref_file = './datasets/Mixamo/{}/{}'.format(dest_name, bvh_name)

    main(input_file, ref_file, pjoin(output_path, 'result.bvh'), test_type)


example('BigVegas', 'Mousey_m', 'Dual Weapon Combo.bvh', 'cross', './examples/cross_structure')
print('Finished!')
